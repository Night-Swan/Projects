{"cells":[{"cell_type":"markdown","metadata":{"id":"Djq4kjiGtLt8"},"source":["Loading images, pruning saved model & quatizing pruned model:\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"BFIApxioLilQ","outputId":"76d0a870-ade8-494e-8caf-43c8e8bf61fb","executionInfo":{"status":"ok","timestamp":1720088701222,"user_tz":-120,"elapsed":137999,"user":{"displayName":"Tijn Hassing","userId":"18415421979212976140"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow==2.11.0\n","  Downloading tensorflow-2.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (24.3.25)\n","Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.11.0)\n","  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.64.1)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (3.9.0)\n","Collecting keras<2.12,>=2.11.0 (from tensorflow==2.11.0)\n","  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (18.1.1)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.25.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (24.1)\n","Collecting protobuf<3.20,>=3.9.2 (from tensorflow==2.11.0)\n","  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.16.0)\n","Collecting tensorboard<2.12,>=2.11 (from tensorflow==2.11.0)\n","  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-estimator<2.12,>=2.11.0 (from tensorflow==2.11.0)\n","  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (0.37.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.11.0) (0.43.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.27.0)\n","Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.12,>=2.11->tensorflow==2.11.0)\n","  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.31.0)\n","Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.12,>=2.11->tensorflow==2.11.0)\n","  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.12,>=2.11->tensorflow==2.11.0)\n","  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.0.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2024.6.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.1.5)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.2.2)\n","Installing collected packages: tensorboard-plugin-wit, tensorflow-estimator, tensorboard-data-server, protobuf, keras, gast, google-auth-oauthlib, tensorboard, tensorflow\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.15.0\n","    Uninstalling tensorflow-estimator-2.15.0:\n","      Successfully uninstalled tensorflow-estimator-2.15.0\n","  Attempting uninstall: tensorboard-data-server\n","    Found existing installation: tensorboard-data-server 0.7.2\n","    Uninstalling tensorboard-data-server-0.7.2:\n","      Successfully uninstalled tensorboard-data-server-0.7.2\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.20.3\n","    Uninstalling protobuf-3.20.3:\n","      Successfully uninstalled protobuf-3.20.3\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.15.0\n","    Uninstalling keras-2.15.0:\n","      Successfully uninstalled keras-2.15.0\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.6.0\n","    Uninstalling gast-0.6.0:\n","      Successfully uninstalled gast-0.6.0\n","  Attempting uninstall: google-auth-oauthlib\n","    Found existing installation: google-auth-oauthlib 1.2.0\n","    Uninstalling google-auth-oauthlib-1.2.0:\n","      Successfully uninstalled google-auth-oauthlib-1.2.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.15.2\n","    Uninstalling tensorboard-2.15.2:\n","      Successfully uninstalled tensorboard-2.15.2\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.15.0\n","    Uninstalling tensorflow-2.15.0:\n","      Successfully uninstalled tensorflow-2.15.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires protobuf<5,>=3.20, but you have protobuf 3.19.6 which is incompatible.\n","google-cloud-pubsub 2.21.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n","googleapis-common-protos 1.63.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n","grpc-google-iam-v1 0.13.1 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n","pandas-gbq 0.19.2 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n","tensorflow-datasets 4.9.6 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n","tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 3.19.6 which is incompatible.\n","tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.11.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-0.4.6 keras-2.11.0 protobuf-3.19.6 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]},"id":"c5c2d9af1f664c538974dd220de5d367"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: keras==2.11.0 in /usr/local/lib/python3.10/dist-packages (2.11.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n"]}],"source":["%pip install tensorflow==2.11.0\n","%pip install keras==2.11.0\n","%pip install matplotlib\n","%pip install numpy\n","%pip install scikit-learn\n","%pip install opencv-python\n"]},{"cell_type":"markdown","metadata":{"id":"6B1QU6HQkH-i"},"source":["image loader file\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":332},"id":"k1BS_9t-jtBf","outputId":"13b0db13-be1c-4820-94e8-dfaa4bd0c270","executionInfo":{"status":"error","timestamp":1720088937295,"user_tz":-120,"elapsed":263,"user":{"displayName":"Tijn Hassing","userId":"18415421979212976140"}}},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'C://Users//tijnh//Documents//mod8//new_data//new_data/train'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-17cce57da561>\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images_and_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-17cce57da561>\u001b[0m in \u001b[0;36mload_images_and_labels\u001b[0;34m(main_dir)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0msubdir_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mimage_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_filenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C://Users//tijnh//Documents//mod8//new_data//new_data/train'"]}],"source":["import cv2\n","import numpy as np\n","import os\n","import matplotlib.pyplot as plt\n","\n","#change with your own directory with the dataset while grading\n","main_dir = 'C://Users//joris//Downloads//dataset//dataset'\n","\n","#converts training set to grayscale\n","def preprocess_image(image_path):\n","    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n","    image = cv2.resize(image, (32, 32))\n","    image = image / 255.0\n","    image = np.stack((image,) * 3, axis=-1)\n","    return image\n","\n","\n","#loads and labels all the images\n","def load_images_and_labels(main_dir):\n","    images = []\n","    labels = []\n","\n","    for subdir in ['train', 'test', 'valid']:\n","        subdir_path = os.path.join(main_dir, subdir)\n","        image_filenames = [f for f in os.listdir(subdir_path) if f.endswith(\".jpg\") or f.endswith(\".png\")]\n","\n","        for filename in sorted(image_filenames):\n","            image_path = os.path.join(subdir_path, filename)\n","            image = preprocess_image(image_path)\n","            images.append(image)\n","            labels.append(ord(filename[0].upper()) - ord('A'))\n","\n","    return np.array(images), np.array(labels)\n","\n","\n","\n","images, labels = load_images_and_labels(main_dir)\n","\n","\n","def visualize_images(images, num_images):\n","    plt.figure(figsize=(num_images * 4, 4))\n","    for i in range(num_images):\n","        ax = plt.subplot(2, num_images, i + 1)\n","        plt.imshow(images[i])\n","        plt.title(\"Original\")\n","        plt.axis(\"off\")\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","x_combined, y_combined = load_images_and_labels(main_dir)"]},{"cell_type":"markdown","metadata":{"id":"-X9E_DHrkKiP"},"source":["shapes the images into train test and val"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Q5j8wWSjpAp","outputId":"9f97c5dd-d574-4c3b-d29c-3e60520059d0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training data shape: (1677, 32, 32, 3), (1677, 29)\n","Validation data shape: (17, 32, 32, 3), (17, 29)\n","Test data shape: (34, 32, 32, 3), (34, 29)\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.preprocessing import LabelEncoder\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import json\n","import os\n","\n","os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n","\n","# Convert labels to numerical format\n","num_classes = 29\n","one_hot_labels = to_categorical(y_combined, num_classes=num_classes)\n","\n","# Split the data\n","total_samples = x_combined.shape[0]\n","num_test = int(0.02 * total_samples)\n","num_val = int(0.01 * total_samples)\n","num_train = total_samples - num_test - num_val\n","\n","x_train = x_combined[:num_train]\n","y_train = one_hot_labels[:num_train]\n","\n","x_val = x_combined[num_train:num_train + num_val]\n","y_val = one_hot_labels[num_train:num_train + num_val]\n","\n","x_test = x_combined[num_train + num_val:]\n","y_test = one_hot_labels[num_train + num_val:]\n","\n","print(f\"Training data shape: {x_train.shape}, {y_train.shape}\")\n","print(f\"Validation data shape: {x_val.shape}, {y_val.shape}\")\n","print(f\"Test data shape: {x_test.shape}, {y_test.shape}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FLqFrcXQQsVv"},"outputs":[],"source":["%pip install tensorflow==2.11.0\n","%pip install keras==2.11.0\n","%pip install matplotlib\n","%pip install numpy\n","%pip install scikit-learn\n","%pip install opencv-python"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p7kLUMPXQsVv"},"outputs":[],"source":["!pip install tensorflow_model_optimization"]},{"cell_type":"markdown","metadata":{"id":"AJMf6go4QsVw"},"source":["Pruning code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1dFbHdjsQsVw"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import tensorflow_model_optimization as tfmot\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.optimizers import Adam\n","\n","def create_model():\n","    model = tf.keras.models.Sequential()\n","    model.add(Conv2D(filters=32, kernel_size=(5, 5), padding='same', activation='relu', input_shape=(32, 32, 3)))\n","    model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n","    model.add(Conv2D(filters=64, kernel_size=(5, 5), padding='same', activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n","    model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n","    model.add(Flatten())\n","    model.add(Dropout(0.5))\n","    model.add(Dense(64, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(32, activation='relu'))\n","    model.add(Dense(29, activation='softmax'))\n","\n","    return model\n","\n","batch_size = 64\n","\n","def pruning_parameters(sparsity, epochs):\n","    validation_split = 0.1  # 10% of the training set will be used for validation set.\n","    num_images = len(x_train) * (1 - validation_split)\n","    end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n","    # Set the parameters for pruning\n","    pruning_params = {\n","        'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n","            initial_sparsity=0.01,\n","            final_sparsity=sparsity,\n","            begin_step=0,\n","            end_step=end_step\n","        )\n","    }\n","    return pruning_params\n","\n","def pruning(sparsity_level, epochs, text):\n","    model = create_model()\n","    model.load_weights('final_model_weights.h5')  # Ensure weights are compatible with the model architecture\n","\n","    # Apply pruning\n","    prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n","    pruning_params = pruning_parameters(sparsity_level, epochs)\n","\n","    # Wrap the model with the pruning wrapper\n","    pruned_model = prune_low_magnitude(model, **pruning_params)\n","\n","    # Compile the model\n","    optimizer = Adam(learning_rate=0.001)\n","    pruned_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","    # Define the pruning callbacks\n","    callbacks = [\n","        tfmot.sparsity.keras.UpdatePruningStep(),\n","        tfmot.sparsity.keras.PruningSummaries(log_dir='./logs')\n","    ]\n","\n","    # Fit the model\n","    pruned_model.fit(x_train, y_train,\n","                     batch_size=batch_size,\n","                     epochs=epochs,\n","                     validation_split=0.1,\n","                     callbacks=callbacks)\n","\n","    # Evaluate the model\n","    test_loss, test_accuracy = pruned_model.evaluate(x_test, y_test)\n","    print(f\"Pruning {int(sparsity_level * 100)}% {text} - Accuracy: {test_accuracy:.4f}, Loss: {test_loss:.4f}\")\n","\n","    # Save the pruned model\n","    tf.saved_model.save(pruned_model, 'pruned_model')\n","    print(\"Pruned model saved to 'pruned_model'\")\n","\n","# Call the pruning function\n","pruning(0.5, 2, \"with fine-tuning\")  # Apply pruning with a target sparsity of 50% and 2 epochs for fine-tuning"]},{"cell_type":"markdown","metadata":{"id":"rx3CxsvqQsVx"},"source":["Quantizing code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"45Z4ciOGQsVx","outputId":"0ed725b3-9a58-421f-de3a-5d91089b1fa4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Quantized model saved at C://Users//joris//Downloads//5_layered_model//quantized_5_layered_model.tflite\n"]}],"source":["import tensorflow as tf\n","import numpy as np\n","\n","# Load the Keras model\n","#change with your own directory while grading\n","model_path = 'C://Users//joris//Downloads//final_pruned_model//final_pruned_model'\n","\n","# Convert the model to a TensorFlow Lite model with quantization\n","converter = tf.lite.TFLiteConverter.from_saved_model(model_path)\n","\n","# Set the optimization flag for quantization\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","\n","# Optionally, provide a representative dataset for better quantization accuracy\n","def representative_data_gen():\n","    for input_value in tf.data.Dataset.from_tensor_slices((x_train.astype(np.float32))).batch(1).take(100):\n","        yield [input_value]\n","\n","converter.representative_dataset = representative_data_gen\n","\n","# Convert the model\n","tflite_model = converter.convert()\n","\n","# Save the quantized model\n","# change with your own path while grading\n","quantized_model_path = 'C://Users//joris//Downloads//5_layered_model//quantized_5_layered_model.tflite'\n","with open(quantized_model_path, 'wb') as f:\n","    f.write(tflite_model)\n","\n","print(f\"Quantized model saved at {quantized_model_path}\")\n"]},{"cell_type":"markdown","metadata":{"id":"OF57wEnxQsVx"},"source":["Use the below unix command to covert the model from a ltfile file to a C array\n","\n","xxd -i model_quantized2.tflite > model_data.cc"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"}},"nbformat":4,"nbformat_minor":0}